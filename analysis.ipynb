{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcca Tech Giants HRP Analysis\n",
    "\n",
    "This notebook visualizes the Hierarchical Risk Parity (HRP) process step-by-step.\n",
    "We will:\n",
    "1. Download historical data.\n",
    "2. View the Correlation Matrix.\n",
    "3. Build the Hierarchical Clusters (Dendrogram).\n",
    "4. Optimize the weights.\n",
    "5. Backtest the performance (Equity Curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "from pypfopt import HRPOpt, risk_models\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# Configuration\n",
    "TICKERS = [\n",
    "    'AAPL', 'MSFT', 'NVDA', 'AMZN', 'GOOGL', 'META', 'TSLA', 'BRK-B', 'LLY', 'AVGO', \n",
    "    'JPM', 'UNH', 'V', 'XOM', 'HD', 'PG', 'COST', 'JNJ', 'ABBV', 'MRK', \n",
    "    'AMD', 'WMT', 'KO', 'NFLX', 'BAC', 'PEP', 'CVX', 'TMO', 'CRM', 'WFC', \n",
    "    'LIN', 'CSCO', 'MCD', 'DIS', 'ABT', 'INTU', 'QCOM', 'VZ', 'CMCSA', 'IBM', \n",
    "    'AMAT', 'PFE', 'UBER', 'HON', 'GE', 'UNP', 'TXN', 'NOW', 'SPGI', 'PM'\n",
    "]\n",
    "BENCHMARK = \"SPY\"\n",
    "START_DATE = (pd.Timestamp.now() - pd.DateOffset(years=2)).strftime('%Y-%m-%d')\n",
    "END_DATE = pd.Timestamp.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading data...\")\n",
    "all_tickers = TICKERS + [BENCHMARK]\n",
    "data = yf.download(all_tickers, start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
    "\n",
    "if hasattr(data, \"columns\") and isinstance(data.columns, pd.MultiIndex):\n",
    "     if 'Close' in data.columns.get_level_values(0):\n",
    "         data = data['Close']\n",
    "     elif 'Adj Close' in data.columns.get_level_values(0):\n",
    "         data = data['Adj Close']\n",
    "\n",
    "prices = data[TICKERS].dropna()\n",
    "benchmark = data[BENCHMARK].dropna()\n",
    "\n",
    "print(f\"Data Downloaded. Shape: {prices.shape}\")\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cluster Analysis (Dendrogram)\n",
    "HRP relies on the hierarchical structure of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation\n",
    "returns = prices.pct_change().dropna()\n",
    "corr = returns.corr()\n",
    "\n",
    "# Plot Heatmap\n",
    "fig = px.imshow(corr, text_auto=True, title=\"Asset Correlation Matrix\")\n",
    "fig.show()\n",
    "\n",
    "# Plot Dendrogram\n",
    "fig_dendro = ff.create_dendrogram(corr, labels=corr.columns)\n",
    "fig_dendro.update_layout(title=\"Hierarchical Clustering Dendrogram\")\n",
    "fig_dendro.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimization (HRP)\n",
    "We use `PyPortfolioOpt` to perform the recursive bisection allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = HRPOpt(returns)\n",
    "weights = optimizer.optimize()\n",
    "\n",
    "print(\"Optimized Weights:\")\n",
    "pd.Series(weights).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Backtest (Equity Curve)\n",
    "Comparing the HRP portfolio against the SPY benchmark (Base 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Returns\n",
    "port_weights = pd.Series(weights)\n",
    "port_ret = returns @ port_weights\n",
    "port_cum_ret = (1 + port_ret).cumprod() * 100\n",
    "\n",
    "# Benchmark Returns\n",
    "bench_ret = benchmark.pct_change().dropna()\n",
    "bench_cum_ret = (1 + bench_ret).cumprod() * 100\n",
    "\n",
    "# Align and Plot\n",
    "comparison = pd.DataFrame({\n",
    "    \"HRP Portfolio\": port_cum_ret,\n",
    "    \"SPY\": bench_cum_ret\n",
    "}).dropna()\n",
    "\n",
    "fig = px.line(comparison, title=\"Cumulative Performance (Base 100)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Metrics Comparison\n",
    "Annualized Metrics (Return, Volatility, Sharpe, Sortino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(returns, name=\"Portfolio\"):\n",
    "    # Annualized Return\n",
    "    ann_ret = returns.mean() * 252\n",
    "    \n",
    "    # Annualized Volatility\n",
    "    ann_vol = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe Ratio (Rf=0)\n",
    "    sharpe = ann_ret / ann_vol\n",
    "    \n",
    "    # Sortino Ratio (Rf=0)\n",
    "    downside_returns = returns.copy()\n",
    "    downside_returns[downside_returns > 0] = 0\n",
    "    downside_std = downside_returns.std() * np.sqrt(252)\n",
    "    sortino = ann_ret / downside_std\n",
    "    \n",
    "    return {\n",
    "        \"Return (Ann)\": f\"{ann_ret*100:.2f}%\",\n",
    "        \"Volatility (Ann)\": f\"{ann_vol*100:.2f}%\",\n",
    "        \"Sharpe Ratio\": f\"{sharpe:.2f}\",\n",
    "        \"Sortino Ratio\": f\"{sortino:.2f}\"\n",
    "    }\n",
    "\n",
    "metrics_hrp = calculate_metrics(port_ret, \"HRP\")\n",
    "metrics_spy = calculate_metrics(bench_ret, \"SPY\")\n",
    "\n",
    "results = pd.DataFrame([metrics_hrp, metrics_spy], index=[\"HRP Portfolio\", \"SPY Benchmark\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rolling Allocation (Backtest)\n",
    "Simulating how the HRP allocation would have evolved over time (Rebalanced Monthly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations = []\n",
    "dates = []\n",
    "\n",
    "print(\"Running Rolling Backtest (Monthly Rebalance)...\")\n",
    "# Start from 6 months in to have some data\n",
    "start_idx = 126 \n",
    "rebalance_freq = 21 # Approx 1 month\n",
    "\n",
    "for i in range(start_idx, len(returns), rebalance_freq):\n",
    "    current_date = returns.index[i]\n",
    "    \n",
    "    # Window: All history up to this point (Expanding Window)\n",
    "    # Or Fixed Window (e.g. last 6 months). HRP likes more data for correlation.\n",
    "    # Let's use Expanding Window from start\n",
    "    window_returns = returns.iloc[:i]\n",
    "    \n",
    "    try:\n",
    "        opt = HRPOpt(window_returns)\n",
    "        w = opt.optimize()\n",
    "        allocations.append(w)\n",
    "        dates.append(current_date)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "df_alloc_hist = pd.DataFrame(allocations, index=dates)\n",
    "df_alloc_hist.index.name = \"Date\"\n",
    "\n",
    "# Plot Stacked Area Chart\n",
    "fig_area = px.area(df_alloc_hist, title=\"Asset Allocation Evolution (Expanding HRP)\")\n",
    "fig_area.update_layout(yaxis=dict(range=[0, 1]))\n",
    "fig_area.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}